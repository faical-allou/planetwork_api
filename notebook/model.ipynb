{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4b69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8669c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749800d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-airport_cost\n",
      "test-comp\n",
      "test-config\n",
      "test-demand\n",
      "test-demand_curve\n",
      "test-route_cost\n",
      "test-sked\n",
      "connections\n",
      "preferences\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "param = {}\n",
    "input_directory = '../temp'\n",
    "param_directory = '../param'\n",
    "for _filename in os.listdir(input_directory):\n",
    "    if _filename[0] == '.':\n",
    "        continue\n",
    "    print(_filename)\n",
    "    df_data = pd.read_csv(input_directory+'/'+_filename,  header = None)\n",
    "    filetype = _filename.split('-')[1]\n",
    "    column_dict = { \n",
    "            'sked': ['from', 'to', 'al','fln', 'actype', 'depday','dep','arrday','arr'],\n",
    "            'comp': ['from', 'to', 'al', 'fln','actype', 'depday','dep','arrday','arr'],\n",
    "            'demand': ['orig', 'dest', 'volume','weight', 'rev'],\n",
    "            'demand_curve': ['orig', 'dest', 'ttt_1','ttt_2', 'ttt_3','ttt_4'],          \n",
    "            'route_cost': ['from','to', 'actype', 'value'],\n",
    "            'airport_cost': ['ap', 'actype', 'value'],\n",
    "            'config': ['actype', 'cap_1', 'cap_2']\n",
    "    }\n",
    "    df_data.columns = column_dict[filetype]\n",
    "    data[filetype] = df_data\n",
    "    \n",
    "for _filename in os.listdir(param_directory):\n",
    "    if _filename[0] == '.':\n",
    "        continue\n",
    "    print(_filename)\n",
    "    df_data = pd.read_csv(param_directory+'/'+_filename,  header = None)\n",
    "    column_dict = { \n",
    "            'network' : ['stops_allowed'],\n",
    "            'connections': ['hub', 'minct', 'maxct'],\n",
    "            'preferences' : ['from', 'to', 'nonstop', 'connect']\n",
    "    }\n",
    "    df_data.columns = column_dict[_filename]\n",
    "    param[_filename] = df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e29f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faical\\AppData\\Local\\Temp\\ipykernel_21336\\2961715355.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  full_sked = your_sked.append(comp_sked)\n"
     ]
    }
   ],
   "source": [
    "your_sked = data['sked']\n",
    "comp_sked = data['comp']\n",
    "param_connect = param['connections']\n",
    "\n",
    "full_sked = your_sked.append(comp_sked)\n",
    "full_sked[\"dep\"] = pd.to_datetime(full_sked[\"dep\"]) + full_sked[\"depday\"]*datetime.timedelta(days=1)\n",
    "full_sked[\"arr\"] = pd.to_datetime(full_sked[\"arr\"]) + full_sked[\"arrday\"]*datetime.timedelta(days=1)\n",
    "full_sked[\"id\"] = full_sked['al'] + full_sked['fln'].astype('str')\n",
    "\n",
    "\n",
    "param_connect['minct'] = pd.to_timedelta(param_connect['minct'])\n",
    "param_connect['maxct'] = pd.to_timedelta(param_connect['maxct'])\n",
    "\n",
    "df_connect = full_sked.add_suffix('_1').reset_index(drop=True)\n",
    "df_connect['nbstops'] = 0\n",
    "\n",
    "list_itin = {}\n",
    "list_itin[0] = df_connect\n",
    "\n",
    "#build itineraries\n",
    "for i in range (1,3):\n",
    "    cnx_p = param_connect.copy()\n",
    "    itins = list_itin[i-1].merge(full_sked.add_suffix('_'+str(i+1)), how= \"cross\")\n",
    "    itins['nbstops'] = i\n",
    "    \n",
    "    itins['cnx_time_'+str(i)] = itins['dep_'+str(i+1)] - itins['arr_'+str(i)]\n",
    "    \n",
    "    cnx_p.columns = ['to_'+str(i), 'minct_'+str(i), 'maxct_'+str(i)]\n",
    "    \n",
    "    #filter connections\n",
    "    itins.drop(itins[itins['to_'+str(i)] != itins['from_'+str(i+1)]].index, inplace=True)\n",
    "    itins.drop(itins[itins['from_'+str(i)] == itins['to_'+str(i+1)]].index, inplace=True)\n",
    "    itins.drop(itins[itins['from_'+str(1)] == itins['to_'+str(i+1)]].index, inplace=True)\n",
    "    \n",
    "    itins = itins.merge(cnx_p, on = ['to_'+str(i)])\n",
    "    \n",
    "    itins.drop(itins[itins['cnx_time_'+str(i)] < itins['minct_'+str(i)]].index, inplace=True)\n",
    "    itins.drop(itins[itins['cnx_time_'+str(i)] > itins['maxct_'+str(i)]].index, inplace=True)\n",
    "   \n",
    "    list_itin[i] = itins\n",
    "\n",
    "#add attributes\n",
    "for i in range(0,3):\n",
    "    list_itin[i][\"travel_time\"]=list_itin[i][\"arr_\"+str(i+1)]-list_itin[i][\"dep_1\"]\n",
    "    list_itin[i][\"od\"]=list_itin[i][\"from_1\"]+list_itin[i][\"to_\"+str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ed32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define user arrivals\n",
    "demand_rand = {}\n",
    "demand_curve = data['demand_curve']\n",
    "demand = data['demand']\n",
    "demand_by_ttt = pd.merge(demand, demand_curve, on=[\"orig\",\"dest\"])\n",
    "\n",
    "for i in range(1,5):\n",
    "    demand_by_ttt['d_ttt_'+str(i)]=(demand_by_ttt['ttt_'+str(i)]*demand_by_ttt['volume']).astype('int')\n",
    "\n",
    "#shuffle pax\n",
    "randm = []\n",
    "for i in range(1,5):\n",
    "    for indx, row in demand_by_ttt.iterrows():\n",
    "        for k in range(1,row['d_ttt_'+str(i)]):\n",
    "            randm.append(row['orig']+row['dest'])\n",
    "    random.shuffle(randm)\n",
    "    demand_rand[i] = randm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0a596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae746e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_1</th>\n",
       "      <th>to_1</th>\n",
       "      <th>al_1</th>\n",
       "      <th>fln_1</th>\n",
       "      <th>actype_1</th>\n",
       "      <th>depday_1</th>\n",
       "      <th>dep_1</th>\n",
       "      <th>arrday_1</th>\n",
       "      <th>arr_1</th>\n",
       "      <th>id_1</th>\n",
       "      <th>nbstops</th>\n",
       "      <th>from_2</th>\n",
       "      <th>to_2</th>\n",
       "      <th>al_2</th>\n",
       "      <th>fln_2</th>\n",
       "      <th>actype_2</th>\n",
       "      <th>depday_2</th>\n",
       "      <th>dep_2</th>\n",
       "      <th>arrday_2</th>\n",
       "      <th>arr_2</th>\n",
       "      <th>id_2</th>\n",
       "      <th>cnx_time_1</th>\n",
       "      <th>minct_1</th>\n",
       "      <th>maxct_1</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>od</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUS</td>\n",
       "      <td>CDG</td>\n",
       "      <td>FF</td>\n",
       "      <td>2</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 14:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 17:00:00</td>\n",
       "      <td>FF2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDG</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AF</td>\n",
       "      <td>21</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 18:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 19:15:00</td>\n",
       "      <td>AF21</td>\n",
       "      <td>0 days 01:14:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>0 days 05:01:00</td>\n",
       "      <td>DUSTXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DUS</td>\n",
       "      <td>CDG</td>\n",
       "      <td>LH</td>\n",
       "      <td>2</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 17:00:00</td>\n",
       "      <td>LH2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDG</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AF</td>\n",
       "      <td>21</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 18:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 19:15:00</td>\n",
       "      <td>AF21</td>\n",
       "      <td>0 days 01:14:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>0 days 05:15:00</td>\n",
       "      <td>DUSTXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TXL</td>\n",
       "      <td>CDG</td>\n",
       "      <td>AF</td>\n",
       "      <td>15</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 10:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 12:41:00</td>\n",
       "      <td>AF15</td>\n",
       "      <td>1</td>\n",
       "      <td>CDG</td>\n",
       "      <td>FRA</td>\n",
       "      <td>AF</td>\n",
       "      <td>22</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 16:16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 18:37:00</td>\n",
       "      <td>AF22</td>\n",
       "      <td>0 days 03:35:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>0 days 08:18:00</td>\n",
       "      <td>TXLFRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TXL</td>\n",
       "      <td>CDG</td>\n",
       "      <td>AF</td>\n",
       "      <td>15</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 10:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 12:41:00</td>\n",
       "      <td>AF15</td>\n",
       "      <td>1</td>\n",
       "      <td>CDG</td>\n",
       "      <td>LHR</td>\n",
       "      <td>AF</td>\n",
       "      <td>23</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 15:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 16:32:00</td>\n",
       "      <td>AF23</td>\n",
       "      <td>0 days 02:22:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>0 days 06:13:00</td>\n",
       "      <td>TXLLHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TXL</td>\n",
       "      <td>CDG</td>\n",
       "      <td>AF</td>\n",
       "      <td>15</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 10:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 12:41:00</td>\n",
       "      <td>AF15</td>\n",
       "      <td>1</td>\n",
       "      <td>CDG</td>\n",
       "      <td>MAD</td>\n",
       "      <td>AF</td>\n",
       "      <td>24</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 16:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29 17:34:00</td>\n",
       "      <td>AF24</td>\n",
       "      <td>0 days 04:12:00</td>\n",
       "      <td>0 days 00:15:00</td>\n",
       "      <td>0 days 08:00:00</td>\n",
       "      <td>0 days 07:15:00</td>\n",
       "      <td>TXLMAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from_1 to_1 al_1  fln_1  actype_1  depday_1               dep_1  arrday_1  \\\n",
       "0     DUS  CDG   FF      2       737         1 2022-01-29 14:14:00         1   \n",
       "7     DUS  CDG   LH      2       737         1 2022-01-29 14:00:00         1   \n",
       "16    TXL  CDG   AF     15       380         1 2022-01-29 10:19:00         1   \n",
       "17    TXL  CDG   AF     15       380         1 2022-01-29 10:19:00         1   \n",
       "18    TXL  CDG   AF     15       380         1 2022-01-29 10:19:00         1   \n",
       "\n",
       "                 arr_1  id_1  nbstops from_2 to_2 al_2  fln_2  actype_2  \\\n",
       "0  2022-01-29 17:00:00   FF2        1    CDG  TXL   AF     21       737   \n",
       "7  2022-01-29 17:00:00   LH2        1    CDG  TXL   AF     21       737   \n",
       "16 2022-01-29 12:41:00  AF15        1    CDG  FRA   AF     22       380   \n",
       "17 2022-01-29 12:41:00  AF15        1    CDG  LHR   AF     23       380   \n",
       "18 2022-01-29 12:41:00  AF15        1    CDG  MAD   AF     24       737   \n",
       "\n",
       "    depday_2               dep_2  arrday_2               arr_2  id_2  \\\n",
       "0          1 2022-01-29 18:14:00         1 2022-01-29 19:15:00  AF21   \n",
       "7          1 2022-01-29 18:14:00         1 2022-01-29 19:15:00  AF21   \n",
       "16         1 2022-01-29 16:16:00         1 2022-01-29 18:37:00  AF22   \n",
       "17         1 2022-01-29 15:03:00         1 2022-01-29 16:32:00  AF23   \n",
       "18         1 2022-01-29 16:53:00         1 2022-01-29 17:34:00  AF24   \n",
       "\n",
       "        cnx_time_1         minct_1         maxct_1     travel_time      od  \n",
       "0  0 days 01:14:00 0 days 00:15:00 0 days 08:00:00 0 days 05:01:00  DUSTXL  \n",
       "7  0 days 01:14:00 0 days 00:15:00 0 days 08:00:00 0 days 05:15:00  DUSTXL  \n",
       "16 0 days 03:35:00 0 days 00:15:00 0 days 08:00:00 0 days 08:18:00  TXLFRA  \n",
       "17 0 days 02:22:00 0 days 00:15:00 0 days 08:00:00 0 days 06:13:00  TXLLHR  \n",
       "18 0 days 04:12:00 0 days 00:15:00 0 days 08:00:00 0 days 07:15:00  TXLMAD  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_itin[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75e9cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_ = list(range(1,1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a0ea016",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "random.shuffle(array_)\n",
    "end = time.time()\n",
    "delta = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d40079a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3008878231048584"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ca161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def connection_builder(your_sked, comp_sked, param_connect):\n",
    "    your_sked = data['sked']\n",
    "    comp_sked = data['comp']\n",
    "    param_connect = param['connections']\n",
    "\n",
    "\n",
    "    #create df from data\n",
    "    full_sked = your_sked.append(comp_sked)\n",
    "    df_connect[\"dep\"] = pd.to_datetime(df_connect[\"dep\"]) + df_connect[\"depday\"]*datetime.timedelta(days=1)\n",
    "    df_connect[\"arr\"] = pd.to_datetime(df_connect[\"arr\"]) + df_connect[\"arrday\"]*datetime.timedelta(days=1)\n",
    "    \n",
    "    df_connect = your_sked.copy()\n",
    "    df_connect = df_connect.append(comp_sked)\n",
    "    df2ndleg = your_sked.copy()\n",
    "    df2ndleg = df2ndleg.append(comp_sked) \n",
    "    \n",
    "    df_connect = df_connect.merge(df2ndleg, how='cross')\n",
    "    df_param = param_connect\n",
    "\n",
    "    #convert formats and create new fields\n",
    "    df_connect[\"dep_x\"] = pd.to_datetime(df_connect[\"dep_x\"]) + df_connect[\"day_x\"]*datetime.timedelta(days=1)\n",
    "    df_connect[\"arr_x\"] = pd.to_datetime(df_connect[\"arr_x\"]) + df_connect[\"day_x\"]*datetime.timedelta(days=1)\n",
    "    df_connect[\"dep_y\"] = pd.to_datetime(df_connect[\"dep_y\"]) + df_connect[\"day_y\"]*datetime.timedelta(days=1)\n",
    "    df_connect[\"arr_y\"] = pd.to_datetime(df_connect[\"arr_y\"]) + df_connect[\"day_y\"]*datetime.timedelta(days=1)\n",
    "    df_param['minct'] = pd.to_timedelta(df_param['minct'])\n",
    "    df_param['maxct'] = pd.to_timedelta(df_param['maxct'])\n",
    "\n",
    "    df2ndleg.columns = ['from_x', 'to_x', 'al_x', 'actype_x', 'day_x','dep_x','arr_x']\n",
    "    df2ndleg[\"dep_x\"] = pd.to_datetime(df2ndleg[\"dep_x\"]) + df2ndleg[\"day_x\"]*datetime.timedelta(days=1)\n",
    "    df2ndleg[\"arr_x\"] = pd.to_datetime(df2ndleg[\"arr_x\"]) + df2ndleg[\"day_x\"]*datetime.timedelta(days=1)\n",
    "    df2ndleg[\"stops\"] = 0\n",
    "\n",
    "    df_connect['cnx_time'] = df_connect.dep_y - df_connect.arr_x\n",
    "    df_connect['stops'] = 1\n",
    "\n",
    "    #filter connections\n",
    "    df_connect = df_connect.merge(df_param,on=['to_x'] ).copy()\n",
    "    df_connect = df_connect[df_connect.to_x == df_connect.from_y].copy()\n",
    "    df_connect = df_connect[df_connect.from_x != df_connect.to_y].copy()\n",
    "    df_connect = df_connect[df_connect.cnx_time >= df_connect.minct].copy()\n",
    "    df_connect = df_connect[df_connect.cnx_time <= df_connect.maxct].copy()\n",
    "\n",
    "\n",
    "    #create df with all itineraries\n",
    "    df_itin = df_connect.append(df2ndleg).reset_index()\n",
    "\n",
    "    #add fields for itinerary quality\n",
    "    df_itin[\"traveltime\"] = df_itin.arr_x - df_itin.dep_x\n",
    "    df_itin.loc[df_itin['stops']==1, [\"traveltime\"]] = df_itin.arr_y - df_itin.dep_x\n",
    "    df_itin[\"traveltime\"]= pd.to_timedelta(df_itin[\"traveltime\"].copy())\n",
    "    \n",
    "#    return df_itin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
